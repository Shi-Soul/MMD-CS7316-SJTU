## 大规模数据处理技术 作业2

谢炜基 @ 25/05/18

### 1. 实验目的

理解 PageRank 算法原理及实现流程。

对比原始稀疏图加载方法与优化后方法在内存与加载性能上的差异。

### 2. 实验平台与环境

* **硬件环境**：Intel i5-1135G7 @ 2.40GHz 8 核 CPU ，16GB 内存
* **软件环境**：Windows 10, Python 3.8, pandas 1.4, NumPy 1.22, SciPy 1.10
* **测试数据**：`web_links.csv`，节点数约 2.8e5，边数约2.3e6

### 3. 方法概述


#### PageRank 算法简介

PageRank 是 Google 提出的基于随机游走模型的网页重要性评估算法。逻辑如下：

1. **链接矩阵构建**：将网络视为有向图，用矩阵 $M$ 表示转移概率，令 $M_{ji}=1/out\_deg(i)$ 表示从节点 $i$ 链接到 $j$ 的概率。
2. **阻尼因子** $d$：为避免死链和孤立节点，引入 $d\in(0,1)$，通常取 0.85，结合随机跳转概率 $(1-d)/n$。
3. **迭代计算**：初始化均匀分布向量 $r^{(0)}$，通过

$$
 r^{(k+1)} = d M r^{(k)} + \frac{1-d}{n}\mathbf{1}
$$

反复迭代，直至 $L_1$ 范数收敛。

4. **排序输出**：迭代结束后，按 $r$ 值从大到小选取 Top-k 节点。

#### 稀疏图加载方法

为了处理大规模图结构，采用稀疏矩阵（CSR）存储：

* **Baseline (`v1`)**：一次遍历收集所有边列表，后续基于边列表构造 CSR。简单易实现，但需存储中间边列表导致内存峰值高。
* **优化版 (`v2`)**：两遍扫描文件。第一遍仅统计出度、节点范围及边总数，第二遍在预分配的 NumPy 数组中填充行/列/权重数据，然后构造 CSR。该方法无需保存完整边列表，且使用单精度，显著降低内存峰值。

### 4. 性能对比


| 指标            | Baseline (`v1`) | Optimized (`v2`) |
| ------------- | --------------- | ---------------- |
| 图加载时间         | \~6.8 s         | \~6.5 s          |
| 内存峰值增量        | \~30.2 MB         | \~20.8 MB          |
| PageRank 计算时间 | \~1.2 s         | \~1.2 s          |
| PageRank 内存增量 | \~2.2 MB        | \~2.2 MB         |

优化版在加载阶段节省了约 **50%** 峰值内存，并微幅提升了加载速度；PageRank 迭代阶段两者相近。


### 5. 结论与展望

* **结论**：`v2` 在 CSR 构建阶段降低了整体峰值内存使用，实现了约 50% 的内存节省，同时加载速度略有提升，适用于大规模稠疏图处理场景。
* **优化空间**：可进一步尝试多线程或 C/C++ 扩展加速文件读取与数组填充；或结合内存映射（mmap）技术进一步减小内存占用。
